#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Author: Nicholas Pike

Purpose: Analysis data generated by Guido and found on Materials project for
         high-thoughput calculations of the phonon band structure.  We need to 
         extract both structural information, the BEC, and the bader charge from 
         various database files.
         
"""
# import functions
import json
import numpy as np
import numpy.linalg as la
import pandas as pd
import matplotlib.pyplot as plt
from monty.serialization import loadfn
from mendeleev import element
from pymatgen import MPRester


print('Starting program')

# Important variables
MPKEY       = 'R6WVDqIkFCfrTvmG'
DIFF_MIN    = 0.02
# create the database as a dictionary
database    = dict()

print(' Loading databases')
# load already generated databases
with open('bader_data.json') as bader:
    baderdata = json.load(bader)
with open('becs.json') as bec:
    becsdata = json.load(bec)
with open('structure_with_chem_env_simple.json') as structure:
    structuredata = json.load(structure)

print(' Finished loading databases\n')


print('Gathering materials project data')
print(' Program will count each database found...')
# loop through mp-numbers in the simple environment database
c = 0
structdata = loadfn('structure_with_chem_env_simple.json')
for mp_id, struct in structdata.items():
    data_array = []
    
    # open MPRester
    with MPRester(MPKEY) as mp:
        c += 1
        print(c) # a simple counter so we know that MPRester is working
        data = mp.get_data(mp_id)
#        if c >= 75:
#            break
        
        
        # extract some data from materials project
        try:
            get_sym     = data[0]['spacegroup']['crystal_system']
            spgnum      = data[0]['spacegroup']['number']
            formula     = data[0]['pretty_formula']
            bandgap     = data[0]['band_gap']
            volume      = data[0]['volume']
            engatom     = data[0]['energy_per_atom']
        except IndexError:
            continue # should move to the next mp_id 
            
        
        # elastic data from materials project (if available)
        try:
            elastic     = data[0]['elasticity']['elastic_tensor'] # tensor!
            GV          = data[0]['elasticity']['G_Voigt']
            KV          = data[0]['elasticity']['K_Voigt']
            poisson     = data[0]['elasticity']['poisson_ratio']
        except TypeError:
            elastic     = np.full([6,6],np.nan)
            GV          = np.nan
            KV          = np.nan 
            poisson     = np.nan 
       
        try:
            dielectric  = data[0]['diel']['e_total']  # tensor!
        except TypeError:
            dielectric  = np.full([3,3],np.nan)
        
        # extract data from predetermined databases
        atom_charges    = baderdata[mp_id]['total']['atomic_charges']
        bader_ch_trans  = baderdata[mp_id]['total']['bader_charges_transfer'] # array of bader charge for each atom
        bec_charges     = becsdata[mp_id]['data']#gives arrays of all bec for each atom
        strct           = structuredata[mp_id]['structure'] #structure object for mp_number
        coordenv        = structuredata[mp_id]['coordination_environments'] #array
        alatt           = strct['lattice']['a']
        blatt           = strct['lattice']['b']
        clatt           = strct['lattice']['c']
        alpha           = strct['lattice']['alpha']
        beta            = strct['lattice']['beta']
        gamma           = strct['lattice']['gamma']

        
        # manipulation of bec data
        bec_weird = False
        odd_atom  = 0
        atcharge = 0
        coord_env = ''
        zatom   = [0,0,0]
        for i in range(len(atom_charges)):
            first = 0
            odd_atom  = i
            atcharge  = atom_charges[i]
            try:
                coord_env = coordenv[i][0]['ce_symbol']
            except TypeError:
                coord_env = ''
            zatom[0]  = np.real(la.eig(bec_charges[i])[0][0])
            zatom[1]  = np.real(la.eig(bec_charges[i])[0][1])
            zatom[2]  = np.real(la.eig(bec_charges[i])[0][2])
            for j in range(3):
                if np.sign(bader_ch_trans[i])  != np.sign(la.eig(bec_charges[i])[0][j]) and np.abs(bader_ch_trans[i] - la.eig(bec_charges[i])[0][j]) >= DIFF_MIN and first == 0:                   
                    first = 1
                    bec_weird = True               
                                                        
        # add data to data_array
        data_array.append(formula)
        data_array.append(bec_weird)
        data_array.append(coord_env)
        data_array.append(get_sym)
        data_array.append(spgnum)
        data_array.append(bandgap)
        data_array.append(volume)
        data_array.append(engatom)
        data_array.append(GV)
        data_array.append(KV)
        data_array.append(poisson)
        data_array.append(elastic[0][1]-elastic[3][3])
        data_array.append(elastic[0][0])
        data_array.append(elastic[1][1])
        data_array.append(elastic[2][2])
        data_array.append(elastic[3][3])
        data_array.append(elastic[4][4])
        data_array.append(elastic[5][5])
        data_array.append(dielectric[0][0])
        data_array.append(dielectric[1][1])
        data_array.append(dielectric[2][2])
        data_array.append(odd_atom)
        data_array.append(atcharge)
        data_array.append(zatom[0])       
        data_array.append(zatom[1])
        data_array.append(zatom[2])
        data_array.append(alatt)
        data_array.append(blatt)
        data_array.append(clatt)
        data_array.append(1.0/alatt**2)
        data_array.append(1.0/blatt**2)
        data_array.append(1.0/clatt**2)
        data_array.append(alpha)
        data_array.append(beta)
        data_array.append(gamma)
        
        # extract physical data about the odd atom
        name = str(structuredata[mp_id]['structure']['sites'][odd_atom]['label'])
        data_array.append(element(name).en_pauling)  
        data_array.append(element(name).en_allen)
        data_array.append(element(name).en_ghosh)
        data_array.append(element(name).group_id)
        data_array.append(element(name).period)
        data_array.append(element(name).electron_affinity)
        data_array.append(element(name).block)
        data_array.append(element(name).vdw_radius)
        data_array.append(element(name).atomic_radius)
        data_array.append(element(name).atomic_weight)
        data_array.append(element(name).atomic_number)
        
    # Add data_array to database
    database[mp_id] = data_array    
    
print('Completed gathering all data.\n')
print('Starting analysis of full database.\n')

columns = ['formula','bec_odd','coord_env',
           'sym','spgnum','Eg','volume','eng/atom','Gvoigt','kvoigt',
           'poisson', 'cauchy','sxx','syy','szz','sxy','syz','sxz','exx','eyy','ezz',
           'odd_atom','atcharge','zxx','zyy','zzz',
           'a','b','c','a^-2','b^-2','c^-2','alpha','beta','gamma','E_p','E_a',
           'E_g','group','period','E_aff','block','R_vdw','R_at','atmass',
           'atnum']

#build dataframe
df = pd.DataFrame.from_dict(database,orient='index',columns=columns)
pd.set_option('display.max_rows',len(columns))
pd.set_option('display.max_columns',len(columns))

print('Generating csv files.')
# note that string based data will be excluded by the dataframe algorithm
fullcorr = df.corr(method='pearson')

# print(fullcorr)
# Dumps data to a csv file
fullcorr.to_csv('database_corr_full.csv')

# Dumps data to a csv file
df.to_csv('database_full.csv')

# We can now extract specific data from our dataframe using pandas
# by searching the column header that contain strings, finding the unique strings,
# and then finding the pearson correlation


strcolumns = [col for col, dt in df.dtypes.items() if dt == object]
boolcolumns = [col for col,dt in df.dtypes.items() if dt == bool]
for col in strcolumns:
    if col != 'formula':  # formula is always unique.. that is way too many files!
        # get column values 
        colvalues = df[col]
        # find unique values
        unicol = np.unique(colvalues)
        # iterate over unique values for that column
        for uniq in unicol:
            # filter database col by its uniq entry
            dffilter = df.loc[df[col]== uniq]
            # dump filtered matrix to a csv file
            dffilter.to_csv('database_filtered_'+col+'_'+uniq+'.csv')
                                 
            # find correlation matrix again
            corr_filter = dffilter.corr(method='pearson')
            # Dumps data to a csv file
            corr_filter.to_csv('pearson_filtered_'+col+'_'+uniq+'.csv')
                        
            # for each unique value in the column, we want to iterate over the 
            # unique boolean types
            for col2 in boolcolumns:
                # get column values
                boolvalues = dffilter[col2]
                # find unique values
                unibool = np.unique(boolvalues)
                for uniq2 in unibool:
                    # filter database again with respect to boolean columns
                    dfBEC = dffilter.loc[dffilter[col2]==uniq2]
                    # dump filtered matrix to a csv file
                    dfBEC.to_csv('database_filtered_'+col+'_'+uniq+'_'+col2+'_'+str(uniq2)+'.csv')
                    # find correlation matrix again
                    corr_BEC= dfBEC.corr(method='pearson')
                    # dump correlation to a file
                    corr_BEC.to_csv('pearson_filtered_'+col+'_'+uniq+'_'+col2+'_'+str(uniq2)+'.csv')
                    lendata = len(dfBEC.index)
                    print(' Number of data with filters %s and %s is %i' %(uniq,uniq2,lendata))





# ends script
        
        